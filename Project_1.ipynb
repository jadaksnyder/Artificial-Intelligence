{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPakWT2BR5Bwi+nsR1WsYXU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jadaksnyder/Artificial-Intelligence/blob/main/Project_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "DwX1LRX2ZKuF",
        "outputId": "9ca84bfe-7de5-420a-eeb6-d6e026f51ad7"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/My Drive/archive.zip'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-c49164146c8c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mextract_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/gtzan_data\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1293\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/archive.zip'"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = \"/content/drive/My Drive/archive.zip\"  # Make sure the file exists here\n",
        "extract_folder = \"/content/gtzan_data\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_folder)\n",
        "\n",
        "print(\"Extraction complete!\")\n",
        "print(os.listdir(extract_folder))  # Check extracted files\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from  google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "P-5iO2Pl0jI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchaudio.transforms as TabError\n",
        "\n",
        "#define 10 genres with an array\n",
        "GENRES = [\"blues\", \"classical\", \"country\", \"disco\", \"hiphop\",\n",
        "          \"jazz\", \"metal\", \"pop\", \"reggae\", \"rock\"]\n",
        "\n",
        "#extract Mel-Frequency Cepstral Coefficients from audio file\n",
        "def extract_features(file_path, n_mfcc=40):\n",
        "  y, sr = librosa.load(file_path, sr=22050) #y = actual audio waveform as numpy array.\n",
        "  mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc) #sr = sampling rate\n",
        "  return np.mean(mfcc.T, axis=0) #return mean over time axis\n",
        "\n",
        "#create dataset class\n",
        "class MusicGenreDataset(Dataset):\n",
        "  def __init__(self, root_dir):\n",
        "    self.root_dir = root_dir\n",
        "    self.data = []\n",
        "\n",
        "    for genre in GENRES:\n",
        "      genre_dir = os.path.join(root_dir, genre)\n",
        "      for file_name in os.listdir(genre_dir):\n",
        "        if file.endswith(\".wav\"):\n",
        "          file_path = os.path.join(genre_dir, file_name)\n",
        "          features = extract_features(file_path)\n",
        "          label = GENRES.index(genre)\n",
        "          self.data.append((features, GENRES.index(genre)))\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    features, label = self.data[idx]\n",
        "    return torch.tensor(self.data[idx][0], dtype=torch.float32), self.data[idx][1]\n",
        "\n",
        "#load the dataset\n",
        "\n",
        "dataset = MusicGenreDataset(\"GTZAN\")\n",
        "\n",
        "#create dataloader\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pbBwByo4787a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "#define the CNN Model\n",
        "class GenreClassifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(GenreClassifier, self).__init__()\n",
        "    self.conv1 = nn.Conv1d(in_channels=40, out_channels=64, kernel_size=3)\n",
        "    self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3)\n",
        "    self.fc1 = nn.Linear(128 * 8, 256)\n",
        "    self.fc2 = nn.Linear(256, len(GENRES))\n",
        "    self.relu = nn.ReLU()\n",
        "    self.pool = nn.MaxPool1d(2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(self.relu(self.conv1(x)))\n",
        "    x = self.pool(self.relu(self.conv2(x)))\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = self.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "\n",
        "#initialize model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = GenreClassifier().to(device)\n",
        "\n",
        "#loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "t3LdpyF7BvIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training the model\n",
        "def train_model(model, dataloader, epochs=10):\n",
        "  model.train()\n",
        "  for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in dataloader:\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "      inputs = inputs.unqueeze(2)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      running_loss += loss.item()\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "      total += labels.size(0)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(dataloader):.4f}, Accuracy: {correct/total:.4f}\")\n",
        "\n",
        "    #train the model\n",
        "    train_model(model, dataloader)"
      ],
      "metadata": {
        "id": "wPvGzsLdDDmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test the model\n",
        "def predict_genre(model, file_path):\n",
        "  model.eval()\n",
        "  mfcc_features = extract_features(file_path)\n",
        "  inputs = torch.tensor(mfcc_features, dtype=torch.float32).unsqueeze(0).unsqueeze(2).to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    output = model(inputs)\n",
        "    _, predicted = torch.max(output, 1)\n",
        "  return GENRES[predicted.item()]\n",
        "\n",
        "test_song = \"/mnt/data/rock.00006.wav\"\n",
        "predicted_genre = predict_genre(model, test_song)\n",
        "print(f\"The predicted genre is: {predicted_genre}\")"
      ],
      "metadata": {
        "id": "0W8I77OdEe8p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}